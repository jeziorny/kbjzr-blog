# AI in The Box: okulary od Meta

Zuck na konferencji dla developerów Meta Connect pokazał nowe gogle [Quest 3](https://about.fb.com/news/2023/09/meet-meta-quest-3-mixed-reality-headset/) (po sporej podwyżce, od teraz także o *mixed reality* jak [te od Apple](/apple-vision-pro/)), ale dla mnie ciekawsze było co innego:

Meta zrobiło wraz z Ray-Banem [okulary](https://about.fb.com/news/2023/09/new-ray-ban-meta-smart-glasses/) zintegrowane z AI.

*[Video demo Meta Ray-Ban Smart Glasses]*

Nie był to gwóźdź programu, ale uważam, że warto się im bliżej przyjrzeć:

• Sam produkt jest *jakby* prostszą wersją gogli do *mixed-reality*. "Jakby" bo nie granie w gry jest tu głównym *use case'm*.

• Wektorem nie jest *metawersum* ale dużo prostszy, bardziej podstawowy sposób zastosowania.

• Okulary pozwalają na interakcję z tym, co widzi noszący - można prosić o opis, tego co się widzi; robić zdjęcia, filmy, livestreamować; tłumaczyć napisy w obcym języku a nawet poprosić o tutorial jak naprawić zepsuty tu-oto kran. Fajne.

Przejdźmy jednak to najważniejszych ficzerów:

1. Cena: $299. Same okulary do robienia zdjęć za trzysta dolków to nie była super mocna propozycja wartości, ale okulary do zdjęć, filmów *oraz z wbudowanym AI* w tej cenie? To już ma zapaszek [klasycznej dysrupcji](https://mitsmr.pl/a/christensen-innowacja-jest-kluczem-do-tego-by-ludzie-stawali-sie-lepsi/D1EboGgwh). Niska cena + prostsze scenariusze użycia.

2. Okulary wyglądają *normalnie*. I do tego można wybrać sobie spośród kilku modeli i rodzajów szkieł. Produkt spełnia - niedocenione w Google Glass - kryterium zasady MAYA, [Most Advanced, Yet Acceptable](https://www.interaction-design.org/literature/article/design-for-the-future-but-balance-it-with-your-users-present). Nie *epatuje* technolgizmem za to fajnie wygląda. Estetyka > użyteczność.

3. AI w pakiecie ze sprzętem. To jest ewidentnie nowy kierunek natarcia na dwa wyzwania jednocześnie: (a.) scenariusze użycia *czata jako UI dla AI* (można *mówić* *w języku naturalnym* do AI o tym, co się widzi) oraz (b.) dyfuzji AI jako oprogramowania (jak sensownie zastosować AI w istniejącym już stosie rozwiązań? Otóż można mówić z AI o tym, co się właśnie *widzi*)*.*  Dzięki temu, że okulary ma się na nosie, ten *bundle* działa dla usera *naturalnie*.

Chyba.

Czytam to zagranie jako próbę przejścia do [Aktu Drugiego historii AI](https://www.sequoiacap.com/article/generative-ai-act-two/): od fajnego, obiecującego demo do zastosowania zintegrowanego ze znanym konsumentowi produktem, w znanym *use case.*

Mamy tu więc: *hardware* jako platformę dla AI, zagranie na dysrupcję względem metawersowej strategii Meta (kek), innowację schowaną w akceptowalnej estetyce.

Całkiem nieźle jak na *side project*.

[Napisz do mnie](mailto:jakub.jeziorny@gmail.com)